I"Û<p><em>When designing and implementing autonomous agents, it is important to keep in mind that <strong>recognition</strong> is not the same as <strong>understanding</strong></em>.</p>

<h2 id="recognition">Recognition</h2>
<p>The definition of <em>recognition</em> is â€œidentification of someone or something from previous encounters or knowledge.â€ The etomology of the word is from the Latin â€œto know againâ€. Recognizing things like commands in programs or hyperlinks in web documents is essential for an agent to accomplish an action.</p>

<p>Importantly, agents can recognize elements in their surroundings (real or virtual) only when they are seeing it <em>again</em>. Agents of all types, including humans, must know something about a thing ahead of time in order to recognize it later. This has important implications for how you can program (or train) an agent.</p>

<p>Conversly, <em>not</em> knowing a thing ahead of time means it is likely agents will not see it in the future. Weâ€™ve probably all had this experience ourselves. Without knowing what to look for, it is difficult to recognize objects around us.</p>

<p>Recognition is required before understanding.</p>

<h2 id="understanding">Understanding</h2>
<p>The defintion for the word <em>understand</em> is â€œperceive the intended meaning of (words, a language, or a speaker).â€ Understanding something implies a grasp of the <em>meaning</em> behind it. For humans, understanding the meaning of a word or phrase is essential for communicating. If you donâ€™t understand the words I am using, you are unlikely to grasp the meaning of what I am saying (or writing).</p>

<p>Meaning is tied to intellect and reasoning. Our understanding depends on our intelligence and our ability to reason about what we see and hear around us.</p>

<p>We sometimes talk about â€œintelligent agentsâ€ or training agents to â€œunderstandâ€ new commands. But, in reality machines do not grasp the meaning of things. They cannot reason about their surroundings. This level of agency is usually called <a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence">â€œartificial general intelligenceâ€</a> or AGI. And, as of this writing anyway, AGI is still only a hypothetical possibility.</p>

<blockquote>
  <p>The good news is that, even without <strong>understanding</strong> we can enhance machine agents by way of <strong>inference</strong>. But Iâ€™ll save that for a future post.</p>
</blockquote>

<h2 id="leveraging-recognition">Leveraging Recognition</h2>
<p>The kind of experiments Iâ€™m working on with the <a href="http://amee-project.github.io">AMEE Project</a> are the ones that leverage an agentâ€™s ability to recognize elements in the environment and, when appropriate, act on those elements. That means designing and implementing agents that have the ability to recognize things. That is, the ability to â€œsee againâ€ things it already knows about.</p>

<p>That means Iâ€™m desgning and building more than just agents, I am also creating vocabularies (sometimes called <em>ontologies</em>). These vocabularies act as the engine of the agent. They provide the  <em>a priori</em> information agents need in order to be successful in an environment â€“ in order to recognize trhings.</p>

<p>And thatâ€™s an important step. Creating environments that can contain recognizable elements and agents can that both recognize and act on those elements is what the AMEE Project is about. However, recognition is only part of the story. Questions like â€œHow does an agent recognize something?â€ and â€œHow does an agent know what to do once it recognizes things?â€ are all key to moving beyond static programs and toward programs that can act on their own â€“ that operate as autonomous agents.</p>

<p>â€“ @mamund</p>

:ET